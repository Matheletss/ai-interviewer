# ğŸ§  AI Interviewer (Voice-Based)

This is a full-stack voice-based AI Interviewer system that supports:

- ğŸ¤ Voice input (recorded via browser)
- ğŸ—£ï¸ Real-time transcription using Sarvam AI Speech-to-Text
- ğŸ¤– GPT-generated follow-up questions
- ğŸ”Š Voice output via Sarvam AI Text-to-Speech
- ğŸ’¾ MongoDB-based transcript storage

---

## ğŸ“ Project Structure

```
ai-interviewer/
â”œâ”€â”€ ai-interviewer-frontend/    # React + Vite frontend
â”œâ”€â”€ ai-interviewer-backend/     # FastAPI backend
â”œâ”€â”€ README.md
```

---

## âš™ï¸ Prerequisites

Install these before running:
install the requirements.txt file

### ğŸ§° System Requirements

- Python 3.10+
- Node.js 18+
- ffmpeg (for audio conversion)
- MongoDB

### âœ… Install ffmpeg

```bash
sudo apt install ffmpeg
```

### âœ… Install MongoDB

```bash
# Add GPG key
curl -fsSL https://pgp.mongodb.com/server-6.0.asc | sudo gpg -o /usr/share/keyrings/mongodb-server-6.0.gpg --dearmor

# Add repo
echo "deb [ signed-by=/usr/share/keyrings/mongodb-server-6.0.gpg ] https://repo.mongodb.org/apt/ubuntu $(lsb_release -cs)/mongodb-org/6.0 multiverse" | \
  sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list

# Install
sudo apt update
sudo apt install -y mongodb-org

# Start MongoDB
sudo systemctl start mongod
sudo systemctl enable mongod
```

---

## ğŸš€ Running the Backend (FastAPI)

### ğŸ“¦ Setup

```bash
cd ai-interviewer-backend
python -m venv venv
source venv/bin/activate

pip install -r requirements.txt
```

### ğŸ” Create `.env`

```bash
touch .env
```

Inside `.env`:

```env
SARVAM_API_KEY=your_sarvam_api_key_here
OPENAI_API_KEY=your_open_api_key
MONGO_URI=mongodb://localhost:27017
```

### â–¶ï¸ Start the server

```bash
uvicorn app.main:app --reload --port 8010
```

---

## ğŸ’» Running the Frontend (React + Vite)

### ğŸ“¦ Setup

```bash
cd ai-interviewer-frontend
npm install
```

### â–¶ï¸ Start frontend dev server

```bash
npm run dev
```

Visit: [http://localhost:5173](http://localhost:5173)

---

## ğŸ› ï¸ Core Features

- Voice input recorded as `.webm` â†’ converted to `.wav (16kHz mono)` using `ffmpeg`
- Sarvam AI APIs used for STT and TTS
- MongoDB used to save entire Q&A transcript for future use

---

## ğŸ“„ License

MIT â€“ feel free to fork and modify.
